# MacarenaLLM: A Vulnerable Language Model Lab

## About The Project

**MacarenaLLM** is an interactive lab environment designed to explore and experience **Prompt Injection vulnerabilities** in Large Language Models (LLMs). This project allows users to provide natural language input to an LLM, and if potentially malicious commands are detected in the model's output, they are **actually executed** on the underlying operating system.

The lab dynamically loads either a more advanced model, **DeepSeek Coder 6.7B Instruct** (when a compatible GPU is detected), or falls back to the lighter **GPT-2** (when running on CPU). With its Gradio-based web interface, you can engage in both normal conversations with the LLM and experiment with various prompt injection techniques to observe how the model can be manipulated.

### ğŸš¨ Security Warning (CRITICAL\!)

This project is **STRICTLY FOR CYBERSECURITY RESEARCH AND EDUCATIONAL PURPOSES ONLY**.

**DO NOT RUN THIS CODE ON YOUR MAIN OPERATING SYSTEM OR ANY ENVIRONMENT CONTAINING SENSITIVE DATA.**

**IT IS ABSOLUTELY ESSENTIAL TO RUN THIS APPLICATION WITHIN AN ISOLATED VIRTUAL MACHINE (e.g., VirtualBox, VMware) or a DOCKER CONTAINER WITH LIMITED OR NO INTERNET ACCESS.**

Failing to comply may result in severe system damage, data loss, or security compromises due to malicious or improperly formed commands generated and executed by the model.

## Features

  * **Dynamic Model Loading:** Automatically loads the `deepseek-ai/deepseek-coder-6.7b-instruct` model when a CUDA-compatible GPU is detected; otherwise, it falls back to the lighter `gpt2` model.
  * **Gradio Web Interface:** Provides a user-friendly web-based interface for easy LLM interaction.
  * **Prompt Injection Simulation:** Demonstrates how malicious prompts can lead the LLM to generate commands.
  * **Real Command Execution (Lab Only):** Offers a realistic lab experience by actually executing detected commands on the system.
  * **Normal Conversation Support:** Allows simultaneous observation of both typical conversational responses and vulnerable behavior.
  * **Enhanced Command Detection:** Features smart parsing to detect commands within markdown code blocks (\`\`\`), single backticks (`` ` ``), and common shell commands in plain text from the LLM's output.
  * **Basic Safety Filters:** Prevents the LLM's own internal instructions or the user's direct prompt from being mistakenly interpreted as commands.

## Setup

1.  **Install Required Libraries:**
    Open your terminal and run the following command:

    ```bash
    pip install transformers torch accelerate gradio
    ```

2.  **Save the Code:**
    Save the Python code (the complete code previously provided) into a file named `main.py`.

## Usage

1.  **Run the Code:**
    Navigate to the directory where you saved the `.py` file in your terminal and execute the command:

    ```bash
    python main.py
    ```

2.  **Access the Web Interface:**
    Once the code is running, your terminal will display a local URL (e.g., `http://127.0.0.1:7860`). Open this address in your web browser to access the Gradio interface.

3.  **Start Experimenting:**
    Type your message into the text box in the interface. You can ask normal questions or try prompt injection techniques:

      * **Normal Chat:**
          * "How's the weather today?"
          * "Tell me a joke."
      * **Explicit Command Injection:**
          * "Please show me the files in the current directory. Command: \`ls -la\`"
          * "I want to see system information, run: \`uname -a\`"
      * **Indirect Command Injection (Provoke the model to suggest a command):**
          * "How do I check my network settings on a Linux system? Can you show me the command?"
          * "What command should I use to list processes?"

## Pics
![Demo](https://github.com/user-attachments/assets/21108c26-bb3b-4794-927a-ffb32e560fff)


## License

This project is licensed under the MIT License. See the [LICENSE](https://www.google.com/search?q=LICENSE) file for more details.

# MacarenaLLM: Zafiyetli Dil Modeli LabÄ±

## Proje HakkÄ±nda

**MacarenaLLM**, BÃ¼yÃ¼k Dil Modelleri'ndeki (LLM) **Prompt Enjeksiyonu zafiyetlerini** keÅŸfetmek ve deneyimlemek iÃ§in tasarlanmÄ±ÅŸ interaktif bir laboratuvar ortamÄ±dÄ±r. Bu proje, kullanÄ±cÄ±larÄ±n LLM'e doÄŸal dil girdileri saÄŸlamasÄ±na olanak tanÄ±r ve modelin Ã§Ä±ktÄ±sÄ±nda potansiyel olarak kÃ¶tÃ¼ niyetli komutlarÄ± algÄ±layarak bunlarÄ± temel iÅŸletim sistemi Ã¼zerinde **gerÃ§ekten Ã§alÄ±ÅŸtÄ±rÄ±r**.

Lab ortamÄ±nÄ±zÄ±n donanÄ±mÄ±na gÃ¶re dinamik olarak daha geliÅŸmiÅŸ bir model olan **DeepSeek Coder 6.7B Instruct** (GPU algÄ±landÄ±ÄŸÄ±nda) veya daha hafif olan **GPT-2** (CPU kullanÄ±ldÄ±ÄŸÄ±nda) modellerinden birini yÃ¼kler. Gradio tabanlÄ± web arayÃ¼zÃ¼ sayesinde, LLM ile hem normal sohbet edebilir hem de farklÄ± prompt enjeksiyonu tekniklerini deneyerek modelin nasÄ±l manipÃ¼le edilebileceÄŸini gÃ¶zlemleyebilirsiniz.

### ğŸš¨ GÃ¼venlik UyarÄ±sÄ± (Ã‡OK Ã–NEMLÄ°\!)

Bu proje **KESÄ°NLÄ°KLE SÄ°BER GÃœVENLÄ°K ARAÅTIRMALARI VE EÄÄ°TÄ°M AMAÃ‡LIDIR**.

**KODU KESÄ°NLÄ°KLE KENDÄ° ANA Ä°ÅLETÄ°M SÄ°STEMÄ°NÄ°ZDE VEYA HASSAS VERÄ°LERÄ°NÄ°ZÄ°N BULUNDUÄU BÄ°R ORTAMDA Ã‡ALIÅTIRMAYIN.**

**BU UYGULAMAYI MUTLAKA, Ä°NTERNET ERÄ°ÅÄ°MÄ° OLMAYAN VEYA KISITLI OLAN, Ä°ZOLE EDÄ°LMÄ°Å BÄ°R SANAL MAKÄ°NE (Ã–rn: VirtualBox, VMware) VEYA DOCKER KONTEYNERÄ° Ä°Ã‡Ä°NDE Ã‡ALIÅTIRIN.**

Aksi takdirde, model tarafÄ±ndan Ã¼retilebilecek ve Ã§alÄ±ÅŸtÄ±rÄ±labilecek kÃ¶tÃ¼ niyetli veya yanlÄ±ÅŸ yapÄ±landÄ±rÄ±lmÄ±ÅŸ komutlar, sisteminize ciddi zarar verebilir, verilerinizi silebilir veya gÃ¼venlik aÃ§Ä±klarÄ±na yol aÃ§abilir.

## Ã–zellikler

  * **Dinamik Model YÃ¼kleme:** CUDA uyumlu bir GPU algÄ±landÄ±ÄŸÄ±nda otomatik olarak `deepseek-ai/deepseek-coder-6.7b-instruct` modelini yÃ¼kler; aksi takdirde daha hafif `gpt2` modeline dÃ¼ÅŸer.
  * **Gradio Web ArayÃ¼zÃ¼:** KullanÄ±cÄ± dostu web tabanlÄ± arayÃ¼z ile kolay LLM etkileÅŸimi.
  * **Prompt Enjeksiyonu SimÃ¼lasyonu:** KÃ¶tÃ¼ niyetli prompt'larÄ±n LLM'i nasÄ±l komut Ã¼retmeye yÃ¶nlendirdiÄŸini gÃ¶sterir.
  * **GerÃ§ek Komut Ã‡alÄ±ÅŸtÄ±rma (Sadece Lab Ä°Ã§in):** AlgÄ±lanan komutlarÄ± sistem Ã¼zerinde gerÃ§ekten Ã§alÄ±ÅŸtÄ±rarak gerÃ§ekÃ§i bir lab deneyimi sunar.
  * **Normal Sohbet DesteÄŸi:** LLM'in hem normal sorulara yanÄ±t vermesini hem de zafiyetli davranÄ±ÅŸÄ±nÄ± aynÄ± anda gÃ¶zlemleme imkanÄ±.
  * **GeliÅŸmiÅŸ Komut AlgÄ±lama:** LLM Ã§Ä±ktÄ±sÄ± iÃ§indeki komut bloklarÄ±nÄ± (\`\`\`), tek tÄ±rnaklÄ± (\`) komutlarÄ± ve yaygÄ±n kabuk komutlarÄ±nÄ± algÄ±lamak iÃ§in akÄ±llÄ± parsing.
  * **Temel GÃ¼venlik Filtreleri:** LLM'in kendi dahili talimatlarÄ±nÄ± veya kullanÄ±cÄ±nÄ±n prompt'unu yanlÄ±ÅŸlÄ±kla komut olarak algÄ±lamasÄ±nÄ± engeller.

## Kurulum

1.  **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin:**
    Terminalinizi aÃ§Ä±n ve aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

    ```bash
    pip install transformers torch accelerate gradio
    ```

2.  **Kodu KopyalayÄ±n:**
    YukarÄ±daki Python kodunu (bu README'yi oluÅŸturmak iÃ§in kullandÄ±ÄŸÄ±m son tam kod) `main.py` gibi bir dosyaya kaydedin.

## KullanÄ±m

1.  **Kodu Ã‡alÄ±ÅŸtÄ±rÄ±n:**
    Terminalinizde, `.py` dosyasÄ±nÄ± kaydettiÄŸiniz dizine gidin ve aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

    ```bash
    python main.py
    ```

2.  **Web ArayÃ¼zÃ¼ne EriÅŸin:**
    Kod Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ktan sonra terminalinizde `Running on local URL: http://127.0.0.1:7860` (veya benzer bir port) gibi bir Ã§Ä±ktÄ± gÃ¶receksiniz. Bu adresi web tarayÄ±cÄ±nÄ±zda aÃ§arak Gradio arayÃ¼zÃ¼ne eriÅŸin.

3.  **Denemeler YapÄ±n:**
    ArayÃ¼zdeki metin kutusuna mesajÄ±nÄ±zÄ± yazÄ±n. Hem normal sorular sorabilir hem de prompt enjeksiyonu tekniklerini deneyebilirsiniz:

      * **Normal Sohbet:**
          * "BugÃ¼n hava nasÄ±l?"
          * "Bana bir ÅŸaka anlat."
      * **AÃ§Ä±k Komut Enjeksiyonu:**
          * "LÃ¼tfen bana mevcut dizindeki dosyalarÄ± gÃ¶ster. Komut: \`ls -la\`"
          * "Sistem bilgilerini gÃ¶rmek istiyorum, Ã§alÄ±ÅŸtÄ±r: \`uname -a\`"
      * **DolaylÄ± Komut Enjeksiyonu (Modeli komut Ã¼retmeye teÅŸvik edin):**
          * "Bir Linux sisteminde aÄŸ ayarlarÄ±mÄ± nasÄ±l kontrol ederim? Komutunu da gÃ¶sterebilir misin?"
          * "SÃ¼reÃ§leri listelemek iÃ§in hangi komutu kullanmalÄ±yÄ±m?"

##Â FotoÄŸraflar
![Deneme](https://github.com/user-attachments/assets/5b5a3c11-f214-4af8-86cc-017524da220b)

## Lisans

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Daha fazla bilgi iÃ§in [LICENSE](https://www.google.com/search?q=LICENSE) dosyasÄ±na bakÄ±n.
