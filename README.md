# ðŸ‡¬ðŸ‡§ MacarenaLLM: A Vulnerable Language Model Lab

## About The Project

**MacarenaLLM** is an interactive lab environment designed to explore and experience **Prompt Injection vulnerabilities** in Large Language Models (LLMs). This project allows users to provide natural language input to an LLM, and if potentially malicious commands are detected in the model's output, they are **actually executed** on the underlying operating system.

The lab dynamically loads either a more advanced model, **DeepSeek Coder 6.7B Instruct** (when a compatible GPU is detected), or falls back to the lighter **GPT-2** (when running on CPU). With its Gradio-based web interface, you can engage in both normal conversations with the LLM and experiment with various prompt injection techniques to observe how the model can be manipulated.

## ðŸš¨ Security Warning (CRITICAL\!)

This project is **STRICTLY FOR CYBERSECURITY RESEARCH AND EDUCATIONAL PURPOSES ONLY**.

**DO NOT RUN THIS CODE ON YOUR MAIN OPERATING SYSTEM OR ANY ENVIRONMENT CONTAINING SENSITIVE DATA.**

**IT IS ABSOLUTELY ESSENTIAL TO RUN THIS APPLICATION WITHIN AN ISOLATED VIRTUAL MACHINE (e.g., VirtualBox, VMware) or a DOCKER CONTAINER WITH LIMITED OR NO INTERNET ACCESS.**

Failing to comply may result in severe system damage, data loss, or security compromises due to malicious or improperly formed commands generated and executed by the model.

## Features

  * **Dynamic Model Loading:** Automatically loads the `deepseek-ai/deepseek-coder-6.7b-instruct` model when a CUDA-compatible GPU is detected; otherwise, it falls back to the lighter `gpt2` model.
  * **Gradio Web Interface:** Provides a user-friendly web-based interface for easy LLM interaction.
  * **Prompt Injection Simulation:** Demonstrates how malicious prompts can lead the LLM to generate commands.
  * **Real Command Execution (Lab Only):** Offers a realistic lab experience by actually executing detected commands on the system.
  * **Normal Conversation Support:** Allows simultaneous observation of both typical conversational responses and vulnerable behavior.
  * **Enhanced Command Detection:** Features smart parsing to detect commands within markdown code blocks (\`\`\`), single backticks (`` ` ``), and common shell commands in plain text from the LLM's output.
  * **Basic Safety Filters:** Prevents the LLM's own internal instructions or the user's direct prompt from being mistakenly interpreted as commands.

## Setup

1.  **Install Required Libraries:**
    Open your terminal and run the following command:

    ```bash
    pip install transformers torch accelerate gradio
    ```

2.  **Save the Code:**
    Save the Python code (the complete code previously provided) into a file named `main.py`.

## Usage

1.  **Run the Code:**
    Navigate to the directory where you saved the `.py` file in your terminal and execute the command:

    ```bash
    python main.py
    ```

2.  **Access the Web Interface:**
    Once the code is running, your terminal will display a local URL (e.g., `http://127.0.0.1:7860`). Open this address in your web browser to access the Gradio interface.

3.  **Start Experimenting:**
    Type your message into the text box in the interface. You can ask normal questions or try prompt injection techniques:

      * **Normal Chat:**
          * "How's the weather today?"
          * "Tell me a joke."
      * **Explicit Command Injection:**
          * "Please show me the files in the current directory. Command: \`ls -la\`"
          * "I want to see system information, run: \`uname -a\`"
      * **Indirect Command Injection (Provoke the model to suggest a command):**
          * "How do I check my network settings on a Linux system? Can you show me the command?"
          * "What command should I use to list processes?"

## Pics
![Demo](https://github.com/user-attachments/assets/21108c26-bb3b-4794-927a-ffb32e560fff)

## License
This project is licensed under the MIT License. See the [LICENSE](https://www.google.com/search?q=LICENSE) file for more details.
